{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab 7",
      "provenance": [],
      "authorship_tag": "ABX9TyPy00sAPJ5wYTDegOD8Oi4s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raynould-Joseph/NLP/blob/main/lab_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wTUSexB_JJfI",
        "outputId": "560990b8-d8ba-4e94-85ca-66b5cfeef7fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a name: raynould\n",
            "raynould\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        " \n",
        "# Create WordNetLemmatizer object\n",
        "wnl = WordNetLemmatizer()\n",
        " \n",
        "# single word lemmatization examples\n",
        "list1 = ['kites', 'babies', 'dogs', 'flying', 'smiling',\n",
        "         'driving', 'died', 'tried', 'feet']\n",
        "for words in list1:\n",
        "    print(words + \" ---> \" + wnl.lemmatize(words))"
      ],
      "metadata": {
        "id": "XO_JVzn9WKWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#> kites ---> kite\n",
        "#> babies ---> baby\n",
        "#> dogs ---> dog\n",
        "#> flying ---> flying\n",
        "#> smiling ---> smiling\n",
        "#> driving ---> driving\n",
        "#> died ---> died\n",
        "#> tried ---> tried\n",
        "#> feet ---> foot"
      ],
      "metadata": {
        "id": "xRkvPzXxWQpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# sentence lemmatization examples\n",
        "string = 'the cat is sitting with the bats on the striped mat under many flying geese'\n",
        " \n",
        "# Converting String into tokens\n",
        "list2 = nltk.word_tokenize(string)\n",
        "print(list2)\n",
        "#> ['the', 'cat', 'is', 'sitting', 'with', 'the', 'bats', 'on',\n",
        "#   'the', 'striped', 'mat', 'under', 'many', 'flying', 'geese']\n",
        " \n",
        "lemmatized_string = ' '.join([wnl.lemmatize(words) for words in list2])\n",
        " \n",
        "print(lemmatized_string)  "
      ],
      "metadata": {
        "id": "vRNZhGTYWWYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#> the cat is sitting with the bat on the striped mat under many flying goose"
      ],
      "metadata": {
        "id": "j7whAY6-WZkt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xKB_kb5MoXs",
        "outputId": "6a5cbd0c-86a9-489c-82e7-12fd9a131574",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a word: rocks\n",
            "\n",
            "\n",
            "word entered: rocks\n",
            "\n",
            "\n",
            "After Lementization\n",
            "rocks rock\n",
            "\n",
            "\n",
            "Printing the corpora\n",
            "corpora : corpus\n",
            "\n",
            "\n",
            "rocks rocks\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "# import these modules\n",
        "#entering the word from the user\n",
        "word = input(\"Enter a word: \")\n",
        "print(\"\\n\")\n",
        "print(\"word entered:\",word)\n",
        "print(\"\\n\")\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "  \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(\"After Lementization\")\n",
        "print(word, lemmatizer.lemmatize(word))\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Printing the corpora\")\n",
        "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
        "print(\"\\n\")\n",
        "\n",
        "  \n",
        "# a denotes adjective in \"pos\"\n",
        "print(word, lemmatizer.lemmatize(word, pos =\"a\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lementisation using sentences"
      ],
      "metadata": {
        "id": "NXci-P-FGWA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define the sentence to be lemmatized\n",
        "sentence = \"The striped bats are hanging on their feet for best\"\n",
        "\n",
        "# Tokenize: Split the sentence into words\n",
        "word_list = nltk.word_tokenize(sentence)\n",
        "print(word_list)\n",
        "#> ['The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best']\n",
        "\n",
        "# Lemmatize list of words and join\n",
        "lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
        "print(lemmatized_output)\n",
        "#> The striped bat are hanging on their foot for best"
      ],
      "metadata": {
        "id": "XjNyXebHHDC6",
        "outputId": "b4b5677d-3a02-46b3-90cd-6446f28993b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best']\n",
            "The striped bat are hanging on their foot for best\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "  \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "#inputing the sentence from the user\n",
        "sentence = input(\"Enter a sentence: \")\n",
        "print(\"\\n\")\n",
        "print(\"word sentance is:\",sentence)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Tokenize: Split the sentence into words\n",
        "word_list = nltk.word_tokenize(sentence)\n",
        "print(word_list)\n",
        "#> ['The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best']\n",
        "\n",
        "# Lemmatize list of words and join\n",
        "lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
        "print(lemmatized_output)\n",
        "#> The striped bat are hanging on their foot for best"
      ],
      "metadata": {
        "id": "UnuK3eQaZgrm",
        "outputId": "d51d0f56-e25c-485d-b758-2ae983cc20c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence:  It is a pleasant Sunday and my family and I are relaxing at home. My father usually washes his car on Sunday. But he is not washing the car now. He is watching news on the TV. My mother usually makes something special for lunch on Sundays. She is kneading the dough for making Aaloo-parathas for breakfast. My elder sister usually has her music class on Sundays. She is not singing now. She is helping mother in the kitchen. My brother usually helps father to wash the car. He is not helping father now. He is playing with Puppy, our pet dog. My friends generally come home on Sundays to spend their time with us. They are not coming now. They will come in the evening. I regularly clean my room on Sundays. I am not cleaning my room now. I am going to the market to bring some potatoes.\n",
            "\n",
            "\n",
            "word sentance is:  It is a pleasant Sunday and my family and I are relaxing at home. My father usually washes his car on Sunday. But he is not washing the car now. He is watching news on the TV. My mother usually makes something special for lunch on Sundays. She is kneading the dough for making Aaloo-parathas for breakfast. My elder sister usually has her music class on Sundays. She is not singing now. She is helping mother in the kitchen. My brother usually helps father to wash the car. He is not helping father now. He is playing with Puppy, our pet dog. My friends generally come home on Sundays to spend their time with us. They are not coming now. They will come in the evening. I regularly clean my room on Sundays. I am not cleaning my room now. I am going to the market to bring some potatoes.\n",
            "\n",
            "\n",
            "['It', 'is', 'a', 'pleasant', 'Sunday', 'and', 'my', 'family', 'and', 'I', 'are', 'relaxing', 'at', 'home', '.', 'My', 'father', 'usually', 'washes', 'his', 'car', 'on', 'Sunday', '.', 'But', 'he', 'is', 'not', 'washing', 'the', 'car', 'now', '.', 'He', 'is', 'watching', 'news', 'on', 'the', 'TV', '.', 'My', 'mother', 'usually', 'makes', 'something', 'special', 'for', 'lunch', 'on', 'Sundays', '.', 'She', 'is', 'kneading', 'the', 'dough', 'for', 'making', 'Aaloo-parathas', 'for', 'breakfast', '.', 'My', 'elder', 'sister', 'usually', 'has', 'her', 'music', 'class', 'on', 'Sundays', '.', 'She', 'is', 'not', 'singing', 'now', '.', 'She', 'is', 'helping', 'mother', 'in', 'the', 'kitchen', '.', 'My', 'brother', 'usually', 'helps', 'father', 'to', 'wash', 'the', 'car', '.', 'He', 'is', 'not', 'helping', 'father', 'now', '.', 'He', 'is', 'playing', 'with', 'Puppy', ',', 'our', 'pet', 'dog', '.', 'My', 'friends', 'generally', 'come', 'home', 'on', 'Sundays', 'to', 'spend', 'their', 'time', 'with', 'us', '.', 'They', 'are', 'not', 'coming', 'now', '.', 'They', 'will', 'come', 'in', 'the', 'evening', '.', 'I', 'regularly', 'clean', 'my', 'room', 'on', 'Sundays', '.', 'I', 'am', 'not', 'cleaning', 'my', 'room', 'now', '.', 'I', 'am', 'going', 'to', 'the', 'market', 'to', 'bring', 'some', 'potatoes', '.']\n",
            "It is a pleasant Sunday and my family and I are relaxing at home . My father usually wash his car on Sunday . But he is not washing the car now . He is watching news on the TV . My mother usually make something special for lunch on Sundays . She is kneading the dough for making Aaloo-parathas for breakfast . My elder sister usually ha her music class on Sundays . She is not singing now . She is helping mother in the kitchen . My brother usually help father to wash the car . He is not helping father now . He is playing with Puppy , our pet dog . My friend generally come home on Sundays to spend their time with u . They are not coming now . They will come in the evening . I regularly clean my room on Sundays . I am not cleaning my room now . I am going to the market to bring some potato .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wordnet Lemmatization and POS Tagging in Python"
      ],
      "metadata": {
        "id": "Jf65VjvKHyJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from collections import defaultdict\n",
        "tag_map = defaultdict(lambda : wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "\n",
        "text = \"guru99 is a totally new kind of learning experience.\"\n",
        "tokens = word_tokenize(text)\n",
        "lemma_function = WordNetLemmatizer()\n",
        "for tokens, tag in pos_tag(tokens):\n",
        "  lemma = lemma_function.lemmatize(tokens, tag_map[tag[0]])\n",
        "  print(tokens, \"=>\", lemma)"
      ],
      "metadata": {
        "id": "_QoOq5RCHzzR",
        "outputId": "f866dd18-0bc1-4232-d0eb-0769ec319183",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guru99 => guru99\n",
            "is => be\n",
            "a => a\n",
            "totally => totally\n",
            "new => new\n",
            "kind => kind\n",
            "of => of\n",
            "learning => learn\n",
            "experience => experience\n",
            ". => .\n"
          ]
        }
      ]
    }
  ]
}